{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bddcbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02ceb838b7e49c4bbeef4d6d7a420eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rohit\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646c821e983540b98d3c747fef7c9bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30411906584945bf902bbc6ed1914e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9694c13db28419e8cd6f31803bac70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23789edaca194dd0a8ccbd5a9b8e2a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ce5d5768b54980b92cab56da2bc228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238ebb9153f040628bda6706f1654bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a3e87838c44b73b276ab7ec553b269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86710c57b0ab4c6ab8085ca279dec546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca095bf366c4f219c7d200318129e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8120cfb177f4dc2a32048edb74f7c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fde7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open(\"../save/dataset.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8059ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5089a8af4e11441a8867ca8fe31921ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = [d['title'] + \" \" + d['text'] for d in data]\n",
    "embeddings = model.encode(dataset, batch_size=256, show_progress_bar=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9400a76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02415119, -0.08757821,  0.03207143, ..., -0.03829419,\n",
       "        -0.00941055, -0.0237251 ],\n",
       "       [ 0.00610825,  0.02204852,  0.01673611, ...,  0.02700167,\n",
       "         0.01581532, -0.04352798],\n",
       "       [ 0.0445008 ,  0.02498521, -0.06588458, ...,  0.07933888,\n",
       "         0.01131955, -0.06754187],\n",
       "       ...,\n",
       "       [ 0.09293563, -0.04406078,  0.0180953 , ..., -0.04813094,\n",
       "        -0.03947265,  0.03651132],\n",
       "       [-0.02716785, -0.0934674 , -0.05820823, ..., -0.02631046,\n",
       "         0.09474543,  0.00533387],\n",
       "       [-0.02047777,  0.00497029,  0.04383397, ...,  0.04277344,\n",
       "         0.0438928 , -0.01252387]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf0939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_embed(doc_ind: int, k: int):\n",
    "    assert k <= 100_000\n",
    "    doc_embed = embeddings[doc_ind]\n",
    "\n",
    "    scores = embeddings @ doc_embed\n",
    "\n",
    "    idx = np.argpartition(scores, -k)[-k:]\n",
    "    order = idx[np.argsort(scores[idx])[::-1]]\n",
    "    \n",
    "    print(f\"Query: {data[doc_ind]['title']}\\n\")\n",
    "    for j in order[1:]:\n",
    "        print(f\"{data[j]['title']} {scores[j]}\")\n",
    "    \n",
    "    return [(scores[i], data[i]['title']) for i in order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e912921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Mary Caffrey Low\n",
      "\n",
      "College of William & Mary fraternity and sorority system 0.6398382782936096\n",
      "Kappa Sigma 0.5969070196151733\n",
      "List of Sigma Alpha Mu chapters 0.5779299736022949\n",
      "Mary Mortimer 0.5113329887390137\n",
      "Sigma Tau 0.4998320937156677\n",
      "Wadleigh High School for Girls 0.4752737283706665\n",
      "Nellie Quander 0.4752534329891205\n",
      "Mount Carroll Seminary 0.47104617953300476\n",
      "Sara Pelham Speaks 0.4642597734928131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0000001, 'Mary Caffrey Low'),\n",
       " (0.6398383, 'College of William & Mary fraternity and sorority system'),\n",
       " (0.596907, 'Kappa Sigma'),\n",
       " (0.57793, 'List of Sigma Alpha Mu chapters'),\n",
       " (0.511333, 'Mary Mortimer'),\n",
       " (0.4998321, 'Sigma Tau'),\n",
       " (0.47527373, 'Wadleigh High School for Girls'),\n",
       " (0.47525343, 'Nellie Quander'),\n",
       " (0.47104618, 'Mount Carroll Seminary'),\n",
       " (0.46425977, 'Sara Pelham Speaks')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_embed(8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387f218b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./save/embeddings.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, embeddings)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.save(\"./save/embeddings.npy\", embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
